{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f90a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.2.0.dev20231027+cu121\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "print('pytorch version:', torch.__version__)\n",
    "global_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', global_device)\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.classification import MultilabelAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f28206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib settings\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "\n",
    "titlesize = 20\n",
    "labelsize = 16\n",
    "legendsize = labelsize\n",
    "xticksize = 14\n",
    "yticksize = xticksize\n",
    "\n",
    "matplotlib.rcParams['legend.markerscale'] = 1.5     # the relative size of legend markers vs. original\n",
    "matplotlib.rcParams['legend.handletextpad'] = 0.5\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4    # the vertical space between the legend entries in fraction of fontsize\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.5       # border whitespace in fontsize units\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['axes.labelsize'] = labelsize\n",
    "matplotlib.rcParams['axes.titlesize'] = titlesize\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=xticksize)\n",
    "matplotlib.rc('ytick', labelsize=yticksize)\n",
    "matplotlib.rc('legend', fontsize=legendsize)\n",
    "\n",
    "matplotlib.rc('font', **{'family':'serif'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d3879",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487259db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval = pd.read_csv('data/train.csv')\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.2, random_state=42)\n",
    "df_train['tags'] = df_train['tags'].apply(lambda x: np.array(list(map(int, x.split(',')))))\n",
    "df_val['tags'] = df_val['tags'].apply(lambda x: np.array(list(map(int, x.split(',')))))\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207ca2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76714/76714 [02:58<00:00, 429.38it/s] \n"
     ]
    }
   ],
   "source": [
    "global_idx2embeds = {} # {idx: np.ndarray[n, 768])}\n",
    "for npy_file in tqdm(glob('data/track_embeddings/*')):\n",
    "    track_idx = int(npy_file.split('\\\\')[1].split('.')[0])\n",
    "    embeds = np.load(npy_file)\n",
    "    global_idx2embeds[track_idx] = embeds[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40907 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40907/40907 [00:20<00:00, 2006.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_train_mean = 0\n",
    "for track_idx in tqdm(df_train['track']):\n",
    "    emb_train_mean += global_idx2embeds[track_idx].mean(axis=0)\n",
    "emb_train_mean /= len(df_train['track'])\n",
    "emb_train_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d838b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_tags, test=False):\n",
    "        self.df_tags = df_tags\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_tags)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        track_idx = self.df_tags.iloc[idx]['track']\n",
    "        embeds = global_idx2embeds[track_idx]\n",
    "        if self.test:\n",
    "            return track_idx, embeds\n",
    "        labels_onehot = np.zeros(256)\n",
    "        labels_onehot[self.df_tags.iloc[idx]['tags']] = 1\n",
    "        return track_idx, embeds, labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85173d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_size = 64\n",
    "def collate(batch):\n",
    "    track_idxs = torch.IntTensor(np.vstack([triplet[0] for triplet in batch]))\n",
    "    embeds_list = []\n",
    "    for triplet in batch:\n",
    "        if triplet[1].shape[0] >= cut_size:\n",
    "            embeds_list.append(torch.FloatTensor(triplet[1][:cut_size]))\n",
    "        else:\n",
    "            repeat_num = cut_size // triplet[1].shape[0] + 1\n",
    "            ext_emb = torch.cat([torch.FloatTensor(triplet[1])] * repeat_num)\n",
    "            embeds_list.append(ext_emb[:cut_size])\n",
    "    embeds = (torch.stack(embeds_list) - emb_train_mean).to(global_device)\n",
    "    labels_onehot = torch.FloatTensor(np.vstack([triplet[2] for triplet in batch])).to(global_device)\n",
    "    return track_idxs, embeds, labels_onehot\n",
    "\n",
    "def collate_test(batch):\n",
    "    track_idxs = torch.IntTensor(np.vstack([triplet[0] for triplet in batch]))\n",
    "    embeds_list = []\n",
    "    for triplet in batch:\n",
    "        if triplet[1].shape[0] >= cut_size:\n",
    "            embeds_list.append(torch.FloatTensor(triplet[1][:cut_size]))\n",
    "        else:\n",
    "            repeat_num = cut_size // triplet[1].shape[0] + 1\n",
    "            ext_emb = torch.cat([torch.FloatTensor(triplet[1])] * repeat_num)\n",
    "            embeds_list.append(ext_emb[:cut_size])\n",
    "    embeds = (torch.stack(embeds_list) - emb_train_mean).to(global_device)\n",
    "    return track_idxs, embeds\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "dataset_train = TrackDataset(df_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size, shuffle=True, collate_fn=collate)\n",
    "\n",
    "dataset_val = TrackDataset(df_val)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size, shuffle=False, collate_fn=collate)\n",
    "dataloader_val_astest = DataLoader(dataset_val, batch_size, shuffle=False, collate_fn=collate_test)\n",
    "\n",
    "dataset_test = TrackDataset(df_test, test=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size, shuffle=False, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68675c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackToTags(pl.LightningModule):\n",
    "    def __init__(self, num_classes=256, input_dim=768, hidden_dim=512, pos_weights=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv_layers = torch.nn.Sequential()  # b x 64 x 768\n",
    "        self.conv_layers.add_module('conv1', torch.nn.Conv2d(1, 4, kernel_size=7))  # b x 1 x 58 x 762\n",
    "        self.conv_layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.conv_layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size=2))  # b x 4 x 29 x 381\n",
    "        self.conv_layers.add_module('conv2', torch.nn.Conv2d(4, 16, kernel_size=6))  # b x 16 x 24 x 376\n",
    "        self.conv_layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.conv_layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size=2))  # b x 16 x 12 x 188\n",
    "        \n",
    "        gru_list = []\n",
    "        for _ in range(16):\n",
    "            gru_list.append(nn.GRU(188, 128, batch_first=True, bidirectional=False, num_layers=1).to(global_device))\n",
    "        self.gru = torch.nn.ModuleList(modules=gru_list)\n",
    "\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(16*128),\n",
    "            nn.Linear(16*128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "            )\n",
    "        \n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.metric = average_precision_score\n",
    "        self._transit_val = {'preds': [], 'labels': []}\n",
    "        \n",
    "    def forward(self, embeds):  # b x 64 x 768\n",
    "        out_conv = self.conv_layers(embeds.unsqueeze(1))  # b x 16 x 12 x 188\n",
    "        s = out_conv.shape\n",
    "        out_gru = torch.FloatTensor(size=(s[0], s[1], s[2], 128)).to(global_device)\n",
    "        for i in range(16): \n",
    "            out_gru[:,i], h = self.gru[i](out_conv[:,i])  # b x 16 x 12 x 128\n",
    "        out_mean = out_gru.mean(dim=2)  # b x 16 x 128\n",
    "        s2 = out_mean.shape\n",
    "        out_mean = out_mean.reshape(s2[0], s2[1]*s2[2])  # b x 16 * 128\n",
    "        outs = self.lin(out_mean)  # b x 256\n",
    "        return outs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        track_idxs, embeds_list, labels_onehot = batch\n",
    "        pred_logits = self(embeds_list)\n",
    "        loss = self.loss(pred_logits, labels_onehot)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        track_idxs, embeds_list, labels_onehot = batch\n",
    "        pred_logits = self(embeds_list)\n",
    "        loss = self.loss(pred_logits, labels_onehot)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        self._transit_val['labels'].append(np.array(labels_onehot.int().cpu()))\n",
    "        self._transit_val['preds'].append(np.array(pred_probs.cpu()))\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = np.vstack(self._transit_val['preds'])\n",
    "        labels = np.vstack(self._transit_val['labels'])\n",
    "        ap = self.metric(labels, preds)\n",
    "        self.log('val_ap', ap, prog_bar=True)\n",
    "        self._transit_val['labels'] = []\n",
    "        self._transit_val['preds'] = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "        \n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                                \"scheduler\": scheduler,\n",
    "                                \"interval\": \"epoch\",\n",
    "                                \"frequency\": 10\n",
    "                                },\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = ModelCheckpoint(dirpath='lightning_logs/cnnrnn_norm/',\n",
    "#                                       filename='{epoch}-{val_loss:.3f}-{val_ap:.3f}', \n",
    "#                                       save_top_k=-1, \n",
    "#                                       monitor=\"val_ap\", \n",
    "#                                       every_n_epochs=1)\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\", devices=1, val_check_interval=1.0, \n",
    "#                      max_epochs=20, log_every_n_steps=100,\n",
    "#                      callbacks=[checkpoint_callback])\n",
    "# model = TrackToTags()\n",
    "# trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrackToTags.load_from_checkpoint('lightning_logs/cnnrnn_norm_2/epoch=3-val_loss=0.048-val_ap=0.199.ckpt')\n",
    "# checkpoint_callback = ModelCheckpoint(dirpath='lightning_logs/cnnrnn_norm_2/',\n",
    "#                                       filename='{epoch}-{val_loss:.3f}-{val_ap:.3f}', \n",
    "#                                       save_top_k=-1, \n",
    "#                                       monitor=\"val_ap\", \n",
    "#                                       every_n_epochs=1)\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\", devices=1, val_check_interval=1.0, \n",
    "#                      max_epochs=20, log_every_n_steps=100,\n",
    "#                      callbacks=[checkpoint_callback])\n",
    "# trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2eddd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.to(global_device)\n",
    "    model.eval()\n",
    "    track_idxs = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_idx, embeds = data\n",
    "            # embeds = [x.to(global_device) for x in embeds]\n",
    "            pred_logits = model(embeds)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            predictions.append(pred_probs.cpu().numpy())\n",
    "            track_idxs.append(track_idx.numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    track_idxs = np.vstack(track_idxs).ravel()\n",
    "    return track_idxs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fa9a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19931837905484265"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_true = np.array([y[2] for y in dataset_val])\n",
    "track_idxs_val, val_pred = predict(model, dataloader_val_astest)\n",
    "average_precision_score(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(val_true[10], val_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred[val_pred < 0.02] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19060376888253802"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "067b1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_idxs, predictions = predict(model.to(global_device), dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "718719fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in zip(track_idxs, predictions)\n",
    "])\n",
    "predictions_df.to_csv('results/prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
